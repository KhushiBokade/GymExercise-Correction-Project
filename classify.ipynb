{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8381f42f-f539-477c-a1f3-d9ae6f26d7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw prediction: push-up, Confidence: 0.80\n",
      "Raw prediction: push-up, Confidence: 0.85\n",
      "Raw prediction: push-up, Confidence: 0.94\n",
      "Raw prediction: push-up, Confidence: 0.95\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.97\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.97\n",
      "Raw prediction: push-up, Confidence: 0.97\n",
      "Raw prediction: push-up, Confidence: 0.99\n",
      "Raw prediction: push-up, Confidence: 0.94\n",
      "Raw prediction: push-up, Confidence: 0.90\n",
      "Raw prediction: push-up, Confidence: 0.95\n",
      "Raw prediction: push-up, Confidence: 0.99\n",
      "Raw prediction: push-up, Confidence: 0.96\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.93\n",
      "Raw prediction: push-up, Confidence: 0.90\n",
      "Raw prediction: push-up, Confidence: 0.88\n",
      "Raw prediction: push-up, Confidence: 0.92\n",
      "Raw prediction: push-up, Confidence: 0.92\n",
      "Raw prediction: push-up, Confidence: 0.87\n",
      "Raw prediction: push-up, Confidence: 0.86\n",
      "Raw prediction: push-up, Confidence: 0.84\n",
      "Raw prediction: push-up, Confidence: 0.79\n",
      "Raw prediction: push-up, Confidence: 0.76\n",
      "Raw prediction: push-up, Confidence: 0.74\n",
      "Raw prediction: push-up, Confidence: 0.70\n",
      "Raw prediction: push-up, Confidence: 0.63\n",
      "Raw prediction: push-up, Confidence: 0.54\n",
      "Raw prediction: push-up, Confidence: 0.54\n",
      "Raw prediction: push-up, Confidence: 0.59\n",
      "Raw prediction: push-up, Confidence: 0.60\n",
      "Raw prediction: push-up, Confidence: 0.63\n",
      "Raw prediction: push-up, Confidence: 0.69\n",
      "Raw prediction: push-up, Confidence: 0.68\n",
      "Raw prediction: push-up, Confidence: 0.64\n",
      "Raw prediction: push-up, Confidence: 0.62\n",
      "Raw prediction: push-up, Confidence: 0.57\n",
      "Raw prediction: push-up, Confidence: 0.60\n",
      "Raw prediction: push-up, Confidence: 0.61\n",
      "Raw prediction: push-up, Confidence: 0.53\n",
      "Raw prediction: push-up, Confidence: 0.56\n",
      "Raw prediction: push-up, Confidence: 0.73\n",
      "Raw prediction: push-up, Confidence: 0.85\n",
      "Raw prediction: push-up, Confidence: 0.88\n",
      "Raw prediction: push-up, Confidence: 0.88\n",
      "Raw prediction: push-up, Confidence: 0.93\n",
      "Raw prediction: push-up, Confidence: 0.83\n",
      "Raw prediction: push-up, Confidence: 0.90\n",
      "Raw prediction: push-up, Confidence: 0.91\n",
      "Raw prediction: push-up, Confidence: 0.91\n",
      "Raw prediction: push-up, Confidence: 0.96\n",
      "Raw prediction: push-up, Confidence: 0.94\n",
      "Raw prediction: push-up, Confidence: 0.93\n",
      "Raw prediction: push-up, Confidence: 0.89\n",
      "Raw prediction: push-up, Confidence: 0.87\n",
      "Raw prediction: push-up, Confidence: 0.91\n",
      "Raw prediction: push-up, Confidence: 0.94\n",
      "Raw prediction: push-up, Confidence: 0.92\n",
      "Raw prediction: push-up, Confidence: 0.90\n",
      "Raw prediction: push-up, Confidence: 0.90\n",
      "Raw prediction: push-up, Confidence: 0.96\n",
      "Raw prediction: push-up, Confidence: 0.93\n",
      "Raw prediction: push-up, Confidence: 0.95\n",
      "Raw prediction: push-up, Confidence: 0.92\n",
      "Raw prediction: push-up, Confidence: 0.93\n",
      "Raw prediction: push-up, Confidence: 0.97\n",
      "Raw prediction: push-up, Confidence: 0.99\n",
      "Raw prediction: push-up, Confidence: 1.00\n",
      "Raw prediction: push-up, Confidence: 0.69\n",
      "Raw prediction: push-up, Confidence: 1.00\n",
      "Raw prediction: push-up, Confidence: 0.89\n",
      "Raw prediction: push-up, Confidence: 0.89\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.97\n",
      "Raw prediction: push-up, Confidence: 0.89\n",
      "Raw prediction: push-up, Confidence: 0.92\n",
      "Raw prediction: push-up, Confidence: 0.96\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import time\n",
    "import collections\n",
    "\n",
    "# Load the trained model and label encoder\n",
    "model = joblib.load(\"exercise_classifier_best.pkl\")\n",
    "le_label = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "\n",
    "# Function to calculate angle between three points\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# Function to extract pose features with torso angle\n",
    "def extract_pose_features(landmarks):\n",
    "    if not landmarks or len(landmarks) < mp_pose.PoseLandmark.RIGHT_ANKLE.value + 1:\n",
    "        return None\n",
    "\n",
    "    left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "    right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "    left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "    right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "    left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "    right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "    left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "               landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "    right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "    left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "    right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "    left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "    right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "    left_shoulder_angle = calculate_angle(left_hip, left_shoulder, left_elbow)\n",
    "    right_shoulder_angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "    left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "    right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "    left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "    right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "    left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "    right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "    left_ankle_angle = calculate_angle(left_knee, left_ankle, [left_ankle[0] + 0.1, left_ankle[1]])\n",
    "    right_ankle_angle = calculate_angle(right_knee, right_ankle, [right_ankle[0] + 0.1, right_ankle[1]])\n",
    "    torso_angle = calculate_angle(left_hip, [(left_shoulder[0] + right_shoulder[0])/2, (left_shoulder[1] + right_shoulder[1])/2], left_knee)\n",
    "\n",
    "    features = pd.DataFrame({\n",
    "        'Shoulder_Angle': [left_shoulder_angle],\n",
    "        'Elbow_Angle': [left_elbow_angle],\n",
    "        'Hip_Angle': [left_hip_angle],\n",
    "        'Knee_Angle': [left_knee_angle],\n",
    "        'Ankle_Angle': [left_ankle_angle],\n",
    "        'Shoulder_Ground_Angle': [right_shoulder_angle],\n",
    "        'Elbow_Ground_Angle': [right_elbow_angle],\n",
    "        'Hip_Ground_Angle': [right_hip_angle],\n",
    "        'Knee_Ground_Angle': [right_knee_angle],\n",
    "        'Ankle_Ground_Angle': [right_ankle_angle],\n",
    "        'Torso_Angle': [torso_angle]\n",
    "    })\n",
    "\n",
    "    expected_order = ['Shoulder_Angle', 'Elbow_Angle', 'Hip_Angle', 'Knee_Angle',\n",
    "                     'Ankle_Angle', 'Shoulder_Ground_Angle', 'Elbow_Ground_Angle',\n",
    "                     'Hip_Ground_Angle', 'Knee_Ground_Angle', 'Ankle_Ground_Angle', 'Torso_Angle']\n",
    "    features = features[expected_order]\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function to classify the pose with adjustable confidence threshold\n",
    "def classify_pose(features):\n",
    "    if features is None or features.empty or features.shape[1] != 11:\n",
    "        return \"Unknown\", 0.0\n",
    "    try:\n",
    "        # Drop Torso_Angle for prediction (assuming model wasn't trained with it)\n",
    "        prediction_features = features.drop(columns=['Torso_Angle'])\n",
    "        prediction = model.predict(prediction_features)[0]\n",
    "        probability = model.predict_proba(prediction_features)[0]\n",
    "        confidence = max(probability)\n",
    "        # Print raw prediction for debugging\n",
    "        print(f\"Raw prediction: {le_label.inverse_transform([prediction])[0]}, Confidence: {confidence:.2f}\")\n",
    "\n",
    "        # Lowered threshold to 0.4 for imperfect postures\n",
    "        if confidence < 0.4:\n",
    "            # Fallback classification based on key angles\n",
    "            elbow_angle = features['Elbow_Angle'].values[0]\n",
    "            shoulder_angle = features['Shoulder_Angle'].values[0]\n",
    "            if 70 < elbow_angle < 150:  # Typical elbow range for push-up\n",
    "                return \"push-up\", 0.4  # Minimum confidence for fallback\n",
    "            elif 90 < shoulder_angle < 180:  # Typical shoulder range for pull-up\n",
    "                return \"pull-up\", 0.4\n",
    "            return \"Unknown\", confidence\n",
    "        exercise = le_label.inverse_transform([prediction])[0]\n",
    "        return exercise, confidence\n",
    "    except Exception as e:\n",
    "        print(f\"Classification error: {e}\")\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "# Function to count repetitions with posture tolerance\n",
    "def count_repetitions(prev_exercise, current_exercise, prev_elbow_angle, current_elbow_angle):\n",
    "    if prev_exercise and current_exercise in [\"push-up\", \"pull-up\"]:\n",
    "        # Adjust threshold for imperfect postures (e.g., 20 degrees instead of 30)\n",
    "        angle_change = abs(current_elbow_angle - prev_elbow_angle)\n",
    "        if angle_change > 20:  # Looser threshold for rep counting\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Main function to process video or webcam with stabilized classification\n",
    "def process_video(source=0):\n",
    "    cap = cv2.VideoCapture(source) if isinstance(source, (int, str)) and source == 0 else cv2.VideoCapture(source)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video source {source}\")\n",
    "        return\n",
    "\n",
    "    cv2.namedWindow('Exercise Classification', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Exercise Classification', 1280, 720)\n",
    "    \n",
    "    prev_exercise = \"Unknown\"\n",
    "    prev_elbow_angle = 0\n",
    "    rep_count = 0\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    exercise_queue = collections.deque(maxlen=5)  # Queue for smoothing over 5 frames\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        frame_count += 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        fps = frame_count / elapsed_time if elapsed_time > 0 else 0\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2)\n",
    "            )\n",
    "\n",
    "            features = extract_pose_features(results.pose_landmarks.landmark)\n",
    "            if features is not None and not features.empty:\n",
    "                exercise, confidence = classify_pose(features)\n",
    "                exercise_queue.append(exercise)\n",
    "                current_elbow_angle = features['Elbow_Angle'].values[0]\n",
    "\n",
    "                # Stabilize exercise label by majority vote over the queue\n",
    "                stabilized_exercise = max(set(exercise_queue), key=exercise_queue.count) if len(exercise_queue) == exercise_queue.maxlen else prev_exercise\n",
    "\n",
    "                if stabilized_exercise in [\"push-up\", \"pull-up\"]:\n",
    "                    rep_count += count_repetitions(prev_exercise, stabilized_exercise, prev_elbow_angle, current_elbow_angle)\n",
    "                    prev_elbow_angle = current_elbow_angle\n",
    "                prev_exercise = stabilized_exercise\n",
    "            else:\n",
    "                stabilized_exercise = \"Unknown\"\n",
    "                confidence = 0.0\n",
    "\n",
    "            cv2.putText(image, f'Exercise: {stabilized_exercise}', (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, f'Confidence: {confidence:.2f}', (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Exercise Classification', image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Use 0 for webcam or provide video file path\n",
    "    video_path = \"video.mp4\"  # Example video (update with correct path, e.g., \"D:/Project/dataset/pull_up/pull-1.mp4\")\n",
    "    process_video(video_path)  # Change to 0 for webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c9f90ba-47b7-4dab-bc3d-ce0687b9c3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw prediction: push-up, Confidence: 0.80\n",
      "Raw prediction: push-up, Confidence: 0.85\n",
      "Raw prediction: push-up, Confidence: 0.94\n",
      "Raw prediction: push-up, Confidence: 0.95\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.97\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.97\n",
      "Raw prediction: push-up, Confidence: 0.97\n",
      "Raw prediction: push-up, Confidence: 0.99\n",
      "Raw prediction: push-up, Confidence: 0.94\n",
      "Raw prediction: push-up, Confidence: 0.90\n",
      "Raw prediction: push-up, Confidence: 0.95\n",
      "Raw prediction: push-up, Confidence: 0.99\n",
      "Raw prediction: push-up, Confidence: 0.96\n",
      "Raw prediction: push-up, Confidence: 0.98\n",
      "Raw prediction: push-up, Confidence: 0.93\n",
      "Raw prediction: push-up, Confidence: 0.90\n",
      "Raw prediction: push-up, Confidence: 0.88\n",
      "Raw prediction: push-up, Confidence: 0.92\n",
      "Raw prediction: push-up, Confidence: 0.92\n",
      "Raw prediction: push-up, Confidence: 0.87\n",
      "Raw prediction: push-up, Confidence: 0.86\n",
      "Raw prediction: push-up, Confidence: 0.84\n",
      "Raw prediction: push-up, Confidence: 0.79\n",
      "Raw prediction: push-up, Confidence: 0.76\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import time\n",
    "import collections\n",
    "\n",
    "# Load the trained model and label encoder\n",
    "model = joblib.load(\"exercise_classifier_best.pkl\")\n",
    "le_label = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.7)\n",
    "\n",
    "# Function to calculate angle between three points\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "    return angle\n",
    "\n",
    "# Function to extract pose features with torso angle\n",
    "def extract_pose_features(landmarks):\n",
    "    if not landmarks or len(landmarks) < mp_pose.PoseLandmark.RIGHT_ANKLE.value + 1:\n",
    "        return None\n",
    "\n",
    "    left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                    landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "    right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "    left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "    right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "    left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "    right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "    left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "               landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "    right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "    left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "    right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "    left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "    right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "    left_shoulder_angle = calculate_angle(left_hip, left_shoulder, left_elbow)\n",
    "    right_shoulder_angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "    left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "    right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "    left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "    right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "    left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "    right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "    left_ankle_angle = calculate_angle(left_knee, left_ankle, [left_ankle[0] + 0.1, left_ankle[1]])\n",
    "    right_ankle_angle = calculate_angle(right_knee, right_ankle, [right_ankle[0] + 0.1, right_ankle[1]])\n",
    "    torso_angle = calculate_angle(left_hip, [(left_shoulder[0] + right_shoulder[0])/2, (left_shoulder[1] + right_shoulder[1])/2], left_knee)\n",
    "\n",
    "    features = pd.DataFrame({\n",
    "        'Shoulder_Angle': [left_shoulder_angle],\n",
    "        'Elbow_Angle': [left_elbow_angle],\n",
    "        'Hip_Angle': [left_hip_angle],\n",
    "        'Knee_Angle': [left_knee_angle],\n",
    "        'Ankle_Angle': [left_ankle_angle],\n",
    "        'Shoulder_Ground_Angle': [right_shoulder_angle],\n",
    "        'Elbow_Ground_Angle': [right_elbow_angle],\n",
    "        'Hip_Ground_Angle': [right_hip_angle],\n",
    "        'Knee_Ground_Angle': [right_knee_angle],\n",
    "        'Ankle_Ground_Angle': [right_ankle_angle],\n",
    "        'Torso_Angle': [torso_angle]\n",
    "    })\n",
    "\n",
    "    expected_order = ['Shoulder_Angle', 'Elbow_Angle', 'Hip_Angle', 'Knee_Angle',\n",
    "                     'Ankle_Angle', 'Shoulder_Ground_Angle', 'Elbow_Ground_Angle',\n",
    "                     'Hip_Ground_Angle', 'Knee_Ground_Angle', 'Ankle_Ground_Angle', 'Torso_Angle']\n",
    "    features = features[expected_order]\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function to classify the pose with adjustable confidence threshold\n",
    "def classify_pose(features):\n",
    "    if features is None or features.empty or features.shape[1] != 11:\n",
    "        return \"Unknown\", 0.0\n",
    "    try:\n",
    "        # Drop Torso_Angle for prediction (assuming model wasn't trained with it)\n",
    "        prediction_features = features.drop(columns=['Torso_Angle'])\n",
    "        prediction = model.predict(prediction_features)[0]\n",
    "        probability = model.predict_proba(prediction_features)[0]\n",
    "        confidence = max(probability)\n",
    "        # Print raw prediction for debugging\n",
    "        print(f\"Raw prediction: {le_label.inverse_transform([prediction])[0]}, Confidence: {confidence:.2f}\")\n",
    "\n",
    "        # Lowered threshold to 0.4 for imperfect postures\n",
    "        if confidence < 0.4:\n",
    "            # Fallback classification based on key angles\n",
    "            elbow_angle = features['Elbow_Angle'].values[0]\n",
    "            shoulder_angle = features['Shoulder_Angle'].values[0]\n",
    "            if 70 < elbow_angle < 150:  # Typical elbow range for push-up\n",
    "                return \"push-up\", 0.4  # Minimum confidence for fallback\n",
    "            elif 90 < shoulder_angle < 180:  # Typical shoulder range for pull-up\n",
    "                return \"pull-up\", 0.4\n",
    "            return \"Unknown\", confidence\n",
    "        exercise = le_label.inverse_transform([prediction])[0]\n",
    "        return exercise, confidence\n",
    "    except Exception as e:\n",
    "        print(f\"Classification error: {e}\")\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "# Function to count repetitions with posture tolerance\n",
    "def count_repetitions(prev_exercise, current_exercise, prev_elbow_angle, current_elbow_angle):\n",
    "    if prev_exercise and current_exercise in [\"push-up\", \"pull-up\"]:\n",
    "        # Adjust threshold for imperfect postures (e.g., 20 degrees instead of 30)\n",
    "        angle_change = abs(current_elbow_angle - prev_elbow_angle)\n",
    "        if angle_change > 20:  # Looser threshold for rep counting\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Main function to process video or webcam with stabilized classification\n",
    "def process_video(source=0):\n",
    "    cap = cv2.VideoCapture(source) if isinstance(source, (int, str)) and source == 0 else cv2.VideoCapture(source)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video source {source}\")\n",
    "        return\n",
    "\n",
    "    cv2.namedWindow('Exercise Classification', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Exercise Classification', 1280, 720)\n",
    "    \n",
    "    prev_exercise = \"Unknown\"\n",
    "    prev_elbow_angle = 0\n",
    "    rep_count = 0\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    exercise_queue = collections.deque(maxlen=5)  # Queue for smoothing over 5 frames\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        frame_count += 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        fps = frame_count / elapsed_time if elapsed_time > 0 else 0\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2)\n",
    "            )\n",
    "\n",
    "            features = extract_pose_features(results.pose_landmarks.landmark)\n",
    "            if features is not None and not features.empty:\n",
    "                exercise, confidence = classify_pose(features)\n",
    "                exercise_queue.append(exercise)\n",
    "                current_elbow_angle = features['Elbow_Angle'].values[0]\n",
    "\n",
    "                # Stabilize exercise label by majority vote over the queue\n",
    "                stabilized_exercise = max(set(exercise_queue), key=exercise_queue.count) if len(exercise_queue) == exercise_queue.maxlen else prev_exercise\n",
    "\n",
    "                if stabilized_exercise in [\"push-up\", \"pull-up\"]:\n",
    "                    rep_count += count_repetitions(prev_exercise, stabilized_exercise, prev_elbow_angle, current_elbow_angle)\n",
    "                    prev_elbow_angle = current_elbow_angle\n",
    "                prev_exercise = stabilized_exercise\n",
    "            else:\n",
    "                stabilized_exercise = \"Unknown\"\n",
    "                confidence = 0.0\n",
    "\n",
    "            cv2.putText(image, f'Exercise: {stabilized_exercise}', (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, f'Confidence: {confidence:.2f}', (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Exercise Classification', image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Use 0 for webcam or provide video file path\n",
    "    video_path = \"video.mp4\"  # Example video (update with correct path, e.g., \"D:/Project/dataset/pull_up/pull-1.mp4\")\n",
    "    process_video(video_path)  # Change to 0 for webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff083b6-6c9e-40c7-94bc-2412fa7c29d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bab6e9a-14e4-4c35-9f43-e25566a55437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved as result\\performance_comparison.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Create result folder if it doesn't exist\n",
    "result_dir = \"result\"\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "# Define the metrics from the classification reports (based on your screenshot)\n",
    "models = ['XGBoost', 'RandomForest']\n",
    "classes = ['pull Up', 'push-up']\n",
    "\n",
    "# Accuracy for both models (from your output: 0.975 78629434673)\n",
    "accuracies = [0.97578629434673, 0.97578629434673]\n",
    "\n",
    "# Precision, Recall, and F1-score for each class and model\n",
    "# Values approximated from your screenshot and graph\n",
    "precision = {\n",
    "    'XGBoost': [0.98, 0.98],\n",
    "    'RandomForest': [0.98, 0.98]\n",
    "}\n",
    "recall = {\n",
    "    'XGBoost': [0.95, 0.99],\n",
    "    'RandomForest': [0.95, 0.99]\n",
    "}\n",
    "f1_score = {\n",
    "    'XGBoost': [0.96, 0.98],\n",
    "    'RandomForest': [0.96, 0.98]\n",
    "}\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Bar positions\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(classes))\n",
    "x_offsets = np.array([-1.5, -0.5, 0.5, 1.5]) * bar_width\n",
    "\n",
    "# Plot bars for each metric\n",
    "bars1 = ax.bar(index + x_offsets[0], [precision['XGBoost'][0], precision['XGBoost'][1]], bar_width, label='XGBoost Precision', color='skyblue')\n",
    "bars2 = ax.bar(index + x_offsets[1], [recall['XGBoost'][0], recall['XGBoost'][1]], bar_width, label='XGBoost Recall', color='lightgreen')\n",
    "bars3 = ax.bar(index + x_offsets[2], [f1_score['XGBoost'][0], f1_score['XGBoost'][1]], bar_width, label='XGBoost F1-Score', color='lightcoral')\n",
    "bars4 = ax.bar(index + x_offsets[0], [precision['RandomForest'][0], precision['RandomForest'][1]], bar_width, label='RandomForest Precision', color='cyan', alpha=0.7)\n",
    "bars5 = ax.bar(index + x_offsets[1], [recall['RandomForest'][0], recall['RandomForest'][1]], bar_width, label='RandomForest Recall', color='limegreen', alpha=0.7)\n",
    "bars6 = ax.bar(index + x_offsets[2], [f1_score['RandomForest'][0], f1_score['RandomForest'][1]], bar_width, label='RandomForest F1-Score', color='salmon', alpha=0.7)\n",
    "\n",
    "# Add accuracy as a horizontal line and text annotation\n",
    "for i, acc in enumerate(accuracies):\n",
    "    ax.axhline(y=acc, xmin=(i-0.4)/2, xmax=(i+0.4)/2, color='purple', linestyle='--', alpha=0.5)\n",
    "    ax.text(i, acc + 0.005, f'Accuracy: {acc:.4f}', ha='center', va='bottom', color='purple', fontsize=10)\n",
    "\n",
    "# Labels and titles\n",
    "ax.set_xlabel('Classes')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_ylim(0.9, 1.0)  # Focus on the relevant range\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.2), ncol=3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2, bars3, bars4, bars5, bars6]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = os.path.join(result_dir, \"performance_comparison.png\")\n",
    "plt.savefig(plot_path, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Graph saved as {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35caaaf-16a3-4082-a434-6823addac6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdfca07-f3c6-4b74-8eda-c8f1233a2f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
